{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%writefile README.md\n",
    "# Behavioral Cloning Project\n",
    "\n",
    "\n",
    "[image1]: ./out/cropped.png \"Cropped Image\"\n",
    "[image2]: ./out/conv1_1.png \"Conv1 Visualization\"\n",
    "[image3]: ./out/conv2_1.png \"Conv2 Visualization\"\n",
    "[image4]: ./out/conv3_1.png \"Conv3 Visualization single channel\"\n",
    "[image5]: ./out/conv4_1.png \"Conv4 Visualization single channel\"\n",
    "[image6]: ./out/history.png \"Recovery Image\"\n",
    "\n",
    "---\n",
    "#### Project files include all required files and can be used to run the simulator in autonomous mode\n",
    "\n",
    "Project includes the following files:\n",
    "* model.py containing the script to create and train the model\n",
    "* drive.py for driving the car in autonomous mode\n",
    "* model.h5 containing a trained convolution neural network\n",
    "* track1 video result track1.mp4\n",
    "* track2 video result track2.mp4\n",
    "* writeup_report.md or writeup_report.pdf summarizing the results\n",
    "\n",
    "---\n",
    "\n",
    "## Model architecture \n",
    "\n",
    "I tried different models and architectures starts from simple architecture to Nvidia and GoogleLenet models and this work decided to implement Nvidia architecture and the discussion part will illustrate the limitations.\n",
    "\n",
    "The following code is the model architectures from `model.py` file. it strats with Normalization Layer followed by cropping layer to make the model focus on the road area. Two convolotion layer with filter `5x5` and depth 24 and 36 followed by `3X3` convolution layer with depth 48. And last two convolution .   \n",
    "\n",
    "the architecture model contain 5 convolutional layers were tuned to perfrom feature extraction and chosen based on a series of experiments that produced diffrent visual output. \n",
    "\n",
    "I used strided convolutions in the first three convolutional layers with a `2×2` stride and a `5×5` kernel for first two layers and `3x3` for third layer. and lastly non-strided convolution layers with\n",
    "`5x5` kernel. It followed by 1 fully connected layers leading to an output control value. Maxpooling layer were used for first 4 convolution layes to speed up processing and grouping areas that has same features. In order to avoiding over-fitting Dropout layers were used after each convolution layer as shown below. \n",
    "\n",
    "```python\n",
    "model.add(Lambda(lambda x: ((x/255)-0.5),input_shape=(160,320,3)))\n",
    "model.add(Cropping2D(cropping=((60,20),(0,0))))\n",
    "model.add(Convolution2D(24,(5,5),strides=3,border_mode='same',activation='elu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Convolution2D(36,(5,5),strides=2,border_mode='same', activation='elu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Convolution2D(48,(3,3),strides=2,border_mode='same',activation='elu'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Convolution2D(64,(5,5),border_mode='same',activation='elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(64,(5,5),border_mode='same',activation='elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500))\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "```\n",
    "The model was tuned dozens of time and `Elu activation` has solved the problem of negative values and which is beneficial for learning and it helps to learn representations that are more robust to noise.\n",
    "The model was tuned to obtain the following output layer as this segmentation for the image is the closest to the real world. \n",
    "![alt text][image1] \n",
    "![alt text][image2]\n",
    "![alt text][image3]\n",
    "![alt text][image4]\n",
    "![alt text][image5]\n",
    "\n",
    "#### Model parameter tuning\n",
    "\n",
    "The model used adam optimizer, so the learning rate was not tuned manually `(model.py line 250)`. Also, as it its regression task the mean square error was chosen for calculating loss.\n",
    "\n",
    "#### Appropriate training data\n",
    "\n",
    "My data were collected for both two tracks and data contains 3 labs for each track in default and reverse  direction and  where augmented and spitted to `X_train,y_train,X_test,y_test`. For avoiding high bias of particular steering angle , the appended images was the all central angles and fliped, non 0.0: right/left cameras and all filliped right/left cameras. this data is not the best as it was taken using Keyboard on slow CPU. Generator was used to generate batches of data in real-time for optimizing the training process time. The total number of data = 32239 and train data= 25791\n",
    "\n",
    "---\n",
    "\n",
    "## Discussion \n",
    "After many trails the good result generated thanks to many tuning to get the output that represent the road segment. in the following output is a 3 segment for road which left off road , right off road and central road and it purposely generated by tubing the filter kernel.\n",
    "\n",
    "The main challenge was with the data as the model clone my behavioral driving included my bad driving part. Correlation angle for right/left cameras were implemented but the result was make the car autonomously driving in zig zag manner. Therefore this model need data taken by joystick and fast computer to avoid any controlling delaying. \n",
    "\n",
    "The final step was to run the simulator to see how well the car was driving around track one. due to low range of zero angles , the vehicle steers left and right with higher rate. however I think due to final output the vehicle drives it self in both tracks in endless of labs and file `Model_summary` contains the model summary and number of tuned parameters.\n",
    "\n",
    "\n",
    "Track1_result: https://www.youtube.com/watch?v=kBO4qfQ5_Y4&t=12s\n",
    "\n",
    "Track2_result: https://www.youtube.com/watch?v=vxQu7oXgCHs&t=106s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
