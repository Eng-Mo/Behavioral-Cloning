{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from random import shuffle\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    print (num_samples)\n",
    "    correlation=0.1\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                name = '.'+batch_sample[0]\n",
    "#                 print(name)\n",
    "                center_image = cv2.imread(name)\n",
    "                center_image=cv2.cvtColor(center_image,cv2.COLOR_BGR2RGB)\n",
    "#                 plt.imshow(center_image)\n",
    "#                 plt.show()\n",
    "              \n",
    "                center_angle = float(batch_sample[3])\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "#                 if center_angle!=0.0:\n",
    "                    \n",
    "                images.append(cv2.flip(center_image,1))\n",
    "                angles.append(center_angle*-1)\n",
    "                \n",
    "                name = '.'+batch_sample[1]\n",
    "#                 print(name)\n",
    "             \n",
    "                left_image = cv2.imread(name)\n",
    "#                 plt.imshow(left_image)\n",
    "#                 plt.show()\n",
    "                left_image=cv2.cvtColor(left_image,cv2.COLOR_BGR2RGB)\n",
    "                left_angle = float(batch_sample[3])\n",
    "                if left_angle !=0.0:\n",
    "#                 if left_angle >=-.2:                        \n",
    "#                     left_angle=left_angle-correlation\n",
    "\n",
    "                    images.append(left_image)\n",
    "                    angles.append(left_angle)\n",
    "                images.append(cv2.flip(left_image,1))\n",
    "                angles.append(left_angle*-1)\n",
    "                name = '.'+batch_sample[2]\n",
    "                right_image = cv2.imread(name)\n",
    "                right_image=cv2.cvtColor(right_image,cv2.COLOR_BGR2RGB)                \n",
    "                right_angle = float(batch_sample[3])\n",
    "                if right_angle!=0.0:  \n",
    "#                 if right_angle <=.2:\n",
    "#                     right_angle=right_angle+correlation\n",
    "\n",
    "                    images.append(right_image)\n",
    "                    angles.append(right_angle)\n",
    "                images.append(cv2.flip(right_image,1))\n",
    "                angles.append(right_angle*-1)\n",
    "                    \n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "#             print(y_train)\n",
    "            sklearn.utils.shuffle(X_train, y_train)\n",
    "            \n",
    "           \n",
    "            yield (X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def layerIntermed_output(inputs,outputs,numch):\n",
    "        intermediate_layer_model= Model(inputs,outputs)\n",
    "    \n",
    "        intermediate_output = intermediate_layer_model.predict(lst0)\n",
    "        print('in shape',intermediate_output.shape)\n",
    "        sampleI=intermediate_output[0]\n",
    "        print(sampleI.shape)\n",
    "        return sampleI[:,:,0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import itertools    \n",
    "from keras.utils import np_utils\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import randint\n",
    "import  tensorflow as tf\n",
    "\n",
    "\n",
    "lines=[]\n",
    "\n",
    "with open ('./testImages/testImages6/driving_log2.csv') as csvfile:\n",
    "    next(csvfile)\n",
    "    reader =csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "with open ('./testImages/testImages7/driving_log.csv') as csvfile:\n",
    "    next(csvfile)\n",
    "    reader =csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "\n",
    "\n",
    "with open ('./testImages/testmages12/driving_log.csv') as csvfile:\n",
    "    next(csvfile)\n",
    "    reader =csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "with open ('./testImages/testImages13/driving_log.csv') as csvfile:\n",
    "    next(csvfile)\n",
    "    reader =csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "with open ('./testImages/testImages14/driving_log.csv') as csvfile:\n",
    "    next(csvfile)\n",
    "    reader =csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "   #### if didnt work multiply filters*2     \n",
    "\n",
    "print(len(lines))\n",
    "\n",
    "images=[]\n",
    "mesurements=[]\n",
    "print(len(lines))\n",
    "\n",
    "train_samples, validation_samples = train_test_split(lines, test_size=0.2) \n",
    "# print(\"tran samples\")\n",
    "# print(len(train_samples))\n",
    "\n",
    "ltrain=len(train_samples)\n",
    "lval=len(validation_samples)\n",
    "\n",
    "train_generator=generator(train_samples)\n",
    "validation_generator = generator(validation_samples)\n",
    "\n",
    "\n",
    "lst = list(itertools.islice(train_generator,1))[0]\n",
    "lst0=lst[0]\n",
    "\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "from keras import backend as k\n",
    "\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D,Convolution2D,Dropout,Activation, Reshape\n",
    "from keras.layers.pooling import MaxPooling2D,AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "from keras import layers\n",
    "\n",
    "embedding_size = 50\n",
    "maxlen=10\n",
    "r= (100, 100,3)\n",
    "model= Sequential()\n",
    "\n",
    "\n",
    "model.add(Lambda(lambda x: ((x/255)-0.5),input_shape=(160,320,3)))\n",
    "model.add(Cropping2D(cropping=((60,20),(0,0))))\n",
    "im = layerIntermed_output(model.input,model.layers[1].output,1) \n",
    "\n",
    "print(im.shape)\n",
    "plt.title(\"copped\")\n",
    "plt.imshow(im,cmap='gray')\n",
    "plt.savefig(\"./out/cropped.png\")\n",
    "plt.show()\n",
    "\n",
    "model.add(Convolution2D(24,(5,5),strides=3,border_mode='same',activation='elu'))\n",
    "\n",
    "\n",
    "im = layerIntermed_output(model.input,model.layers[2].output,3) \n",
    "print(im.shape)\n",
    "plt.title(\"conv1\")\n",
    "plt.imshow(im) \n",
    "plt.savefig(\"./out/conv1_1.png\")\n",
    "plt.show()\n",
    "\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Convolution2D(36,(5,5),strides=2,border_mode='same', activation='elu'))\n",
    "\n",
    "\n",
    "im = layerIntermed_output(model.input,model.layers[5].output,3) \n",
    "print(im.shape)\n",
    "plt.title(\"conv2\")\n",
    "plt.imshow(im) \n",
    "plt.savefig(\"./out/conv2_1.png\")\n",
    "plt.show()\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(48,(3,3),strides=2,border_mode='same',activation='elu'))\n",
    "im = layerIntermed_output(model.input,model.layers[6].output,3) \n",
    "print(im.shape)\n",
    "plt.title(\"conv3\")\n",
    "plt.imshow(im) \n",
    "plt.savefig(\"./out/conv3_1.png\")\n",
    "plt.show()\n",
    "\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(64,(5,5),border_mode='same'\n",
    "                        ,activation='elu'))\n",
    "\n",
    "\n",
    "im = layerIntermed_output(model.input,model.layers[9].output,3) \n",
    "print(im.shape)\n",
    "plt.title(\"conv4\")\n",
    "plt.imshow(im)\n",
    "plt.savefig(\"./out/conv4_1.png\")\n",
    "plt.show()\n",
    "\n",
    "# model.add(MaxPooling2D((2, 2), strides=(1, 1)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# model.add(Convolution2D(64,(5,5),border_mode='same',\n",
    "#                        activation='elu'))\n",
    "\n",
    "\n",
    "# im = layerIntermed_output(model.input,model.layers[10].output,3) \n",
    "# print(im.shape)\n",
    "# plt.title(\"conv6\")\n",
    "# plt.imshow(im) \n",
    "# plt.savefig(\"./out/conv5_1.png\")\n",
    "# plt.show()\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500))\n",
    "model.add(Dense(100))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "history_object= model.fit_generator(train_generator,\n",
    "                                    steps_per_epoch=ltrain,\n",
    "                                    nb_epoch=3,\n",
    "                                    validation_data=validation_generator,\n",
    "                                    nb_val_samples=lval)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.summary()\n",
    "model.save('modelf.h5')\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.savefig(\"./out/data.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.savefig(\"./out/history.png\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
